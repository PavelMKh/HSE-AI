{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "93831896-683d-4946-8cae-7aff56608a65",
      "metadata": {
        "id": "93831896-683d-4946-8cae-7aff56608a65"
      },
      "source": [
        "## ДЗ №2. Матричные факторизации"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03b424ec-3791-4113-a672-25ef7cfa704d",
      "metadata": {
        "id": "03b424ec-3791-4113-a672-25ef7cfa704d"
      },
      "source": [
        "#### В этой домашке вам предстоит реализовать некоторые базовые модели матричной факторизации\n",
        "\n",
        "#### Дата выдачи: 17.02.25\n",
        "\n",
        "#### Мягкий дедлайн: 02.03.25 23:59 MSK\n",
        "\n",
        "#### Жесткий дедлайн: 09.03.25 23:59 MSK"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f4b315-75b8-4225-953c-5510c584ff2b",
      "metadata": {
        "id": "d8f4b315-75b8-4225-953c-5510c584ff2b"
      },
      "source": [
        "В этом задании мы будем работать с классическим для рекоендательных систем датасетом [MovieLens 1M](https://grouplens.org/datasets/movielens/1m/). Датасет содержит рейтинги оценки для 4000 фильмов от 6000 пользователей. Более подробное описание можете найти на странице с датасетом и в README файле"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f5a85f84-4854-4249-963d-143d08bb7e36",
      "metadata": {
        "id": "f5a85f84-4854-4249-963d-143d08bb7e36",
        "outputId": "474077fe-b520-4c9d-8689-3881e1d0aeaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-17 16:56:09--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  25.4MB/s    in 0.2s    \n",
            "\n",
            "2025-02-17 16:56:09 (25.4 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n",
            "SUMMARY\n",
            "================================================================================\n",
            "\n",
            "These files contain 1,000,209 anonymous ratings of approximately 3,900 movies \n",
            "made by 6,040 MovieLens users who joined MovieLens in 2000.\n",
            "\n",
            "USAGE LICENSE\n",
            "================================================================================\n",
            "\n",
            "Neither the University of Minnesota nor any of the researchers\n",
            "involved can guarantee the correctness of the data, its suitability\n",
            "for any particular purpose, or the validity of results based on the\n",
            "use of the data set.  The data set may be used for any research\n",
            "purposes under the following conditions:\n",
            "\n",
            "     * The user may not state or imply any endorsement from the\n",
            "       University of Minnesota or the GroupLens Research Group.\n",
            "\n",
            "     * The user must acknowledge the use of the data set in\n",
            "       publications resulting from the use of the data set\n",
            "       (see below for citation information).\n",
            "\n",
            "     * The user may not redistribute the data without separate\n",
            "       permission.\n",
            "\n",
            "     * The user may not use this information for any commercial or\n",
            "       revenue-bearing purposes without first obtaining permission\n",
            "       from a faculty member of the GroupLens Research Project at the\n",
            "       University of Minnesota.\n",
            "\n",
            "If you have any further questions or comments, please contact GroupLens\n",
            "<grouplens-info@cs.umn.edu>. \n",
            "\n",
            "CITATION\n",
            "================================================================================\n",
            "\n",
            "To acknowledge use of the dataset in publications, please cite the following\n",
            "paper:\n",
            "\n",
            "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History\n",
            "and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4,\n",
            "Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872\n",
            "\n",
            "\n",
            "ACKNOWLEDGEMENTS\n",
            "================================================================================\n",
            "\n",
            "Thanks to Shyong Lam and Jon Herlocker for cleaning up and generating the data\n",
            "set.\n",
            "\n",
            "FURTHER INFORMATION ABOUT THE GROUPLENS RESEARCH PROJECT\n",
            "================================================================================\n",
            "\n",
            "The GroupLens Research Project is a research group in the Department of \n",
            "Computer Science and Engineering at the University of Minnesota. Members of \n",
            "the GroupLens Research Project are involved in many research projects related \n",
            "to the fields of information filtering, collaborative filtering, and \n",
            "recommender systems. The project is lead by professors John Riedl and Joseph \n",
            "Konstan. The project began to explore automated collaborative filtering in \n",
            "1992, but is most well known for its world wide trial of an automated \n",
            "collaborative filtering system for Usenet news in 1996. Since then the project \n",
            "has expanded its scope to research overall information filtering solutions, \n",
            "integrating in content-based methods as well as improving current collaborative \n",
            "filtering technology.\n",
            "\n",
            "Further information on the GroupLens Research project, including research \n",
            "publications, can be found at the following web site:\n",
            "        \n",
            "        http://www.grouplens.org/\n",
            "\n",
            "GroupLens Research currently operates a movie recommender based on \n",
            "collaborative filtering:\n",
            "\n",
            "        http://www.movielens.org/\n",
            "\n",
            "RATINGS FILE DESCRIPTION\n",
            "================================================================================\n",
            "\n",
            "All ratings are contained in the file \"ratings.dat\" and are in the\n",
            "following format:\n",
            "\n",
            "UserID::MovieID::Rating::Timestamp\n",
            "\n",
            "- UserIDs range between 1 and 6040 \n",
            "- MovieIDs range between 1 and 3952\n",
            "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
            "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
            "- Each user has at least 20 ratings\n",
            "\n",
            "USERS FILE DESCRIPTION\n",
            "================================================================================\n",
            "\n",
            "User information is in the file \"users.dat\" and is in the following\n",
            "format:\n",
            "\n",
            "UserID::Gender::Age::Occupation::Zip-code\n",
            "\n",
            "All demographic information is provided voluntarily by the users and is\n",
            "not checked for accuracy.  Only users who have provided some demographic\n",
            "information are included in this data set.\n",
            "\n",
            "- Gender is denoted by a \"M\" for male and \"F\" for female\n",
            "- Age is chosen from the following ranges:\n",
            "\n",
            "\t*  1:  \"Under 18\"\n",
            "\t* 18:  \"18-24\"\n",
            "\t* 25:  \"25-34\"\n",
            "\t* 35:  \"35-44\"\n",
            "\t* 45:  \"45-49\"\n",
            "\t* 50:  \"50-55\"\n",
            "\t* 56:  \"56+\"\n",
            "\n",
            "- Occupation is chosen from the following choices:\n",
            "\n",
            "\t*  0:  \"other\" or not specified\n",
            "\t*  1:  \"academic/educator\"\n",
            "\t*  2:  \"artist\"\n",
            "\t*  3:  \"clerical/admin\"\n",
            "\t*  4:  \"college/grad student\"\n",
            "\t*  5:  \"customer service\"\n",
            "\t*  6:  \"doctor/health care\"\n",
            "\t*  7:  \"executive/managerial\"\n",
            "\t*  8:  \"farmer\"\n",
            "\t*  9:  \"homemaker\"\n",
            "\t* 10:  \"K-12 student\"\n",
            "\t* 11:  \"lawyer\"\n",
            "\t* 12:  \"programmer\"\n",
            "\t* 13:  \"retired\"\n",
            "\t* 14:  \"sales/marketing\"\n",
            "\t* 15:  \"scientist\"\n",
            "\t* 16:  \"self-employed\"\n",
            "\t* 17:  \"technician/engineer\"\n",
            "\t* 18:  \"tradesman/craftsman\"\n",
            "\t* 19:  \"unemployed\"\n",
            "\t* 20:  \"writer\"\n",
            "\n",
            "MOVIES FILE DESCRIPTION\n",
            "================================================================================\n",
            "\n",
            "Movie information is in the file \"movies.dat\" and is in the following\n",
            "format:\n",
            "\n",
            "MovieID::Title::Genres\n",
            "\n",
            "- Titles are identical to titles provided by the IMDB (including\n",
            "year of release)\n",
            "- Genres are pipe-separated and are selected from the following genres:\n",
            "\n",
            "\t* Action\n",
            "\t* Adventure\n",
            "\t* Animation\n",
            "\t* Children's\n",
            "\t* Comedy\n",
            "\t* Crime\n",
            "\t* Documentary\n",
            "\t* Drama\n",
            "\t* Fantasy\n",
            "\t* Film-Noir\n",
            "\t* Horror\n",
            "\t* Musical\n",
            "\t* Mystery\n",
            "\t* Romance\n",
            "\t* Sci-Fi\n",
            "\t* Thriller\n",
            "\t* War\n",
            "\t* Western\n",
            "\n",
            "- Some MovieIDs do not correspond to a movie due to accidental duplicate\n",
            "entries and/or test entries\n",
            "- Movies are mostly entered by hand, so errors and inconsistencies may exist\n"
          ]
        }
      ],
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip\n",
        "!cat ml-1m/README"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "669137ca-f0f9-48d4-ae04-e42a4b0f8d14",
      "metadata": {
        "id": "669137ca-f0f9-48d4-ae04-e42a4b0f8d14"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed65b0ae-ce2d-437a-9739-e7981011089f",
      "metadata": {
        "id": "ed65b0ae-ce2d-437a-9739-e7981011089f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"ml-1m/ratings.dat\", sep='::', names=['user_id', 'item_id', 'rating', 'timestamp'], engine='python')\n",
        "df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "df.drop('timestamp', axis=1, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4988d476-542e-4a32-9c45-7a16bc2a5db5",
      "metadata": {
        "id": "4988d476-542e-4a32-9c45-7a16bc2a5db5"
      },
      "outputs": [],
      "source": [
        "value_counts = df['item_id'].value_counts()\n",
        "filtered_values = value_counts[value_counts > 20].index\n",
        "df = df[df['item_id'].isin(filtered_values)].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e05bd3b-ab2f-4c02-9a97-a4153e9550bc",
      "metadata": {
        "id": "1e05bd3b-ab2f-4c02-9a97-a4153e9550bc"
      },
      "outputs": [],
      "source": [
        "train_end = '2000-12-01'\n",
        "df_train = df[df['datetime'] < train_end].copy()\n",
        "df_test = df[df['datetime'] >= train_end].copy()\n",
        "df_train.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414b8ed7-20d6-4778-9d60-f9c8ccbfa7e3",
      "metadata": {
        "id": "414b8ed7-20d6-4778-9d60-f9c8ccbfa7e3"
      },
      "outputs": [],
      "source": [
        "train_users = df_train['user_id'].unique()\n",
        "train_items = df_train['item_id'].unique()\n",
        "\n",
        "df_test = df_test[df_test['user_id'].isin(train_users)]\n",
        "df_test = df_test[df_test['item_id'].isin(train_items)]\n",
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19f53d61-990c-4626-a470-7eefd06d2ec7",
      "metadata": {
        "id": "19f53d61-990c-4626-a470-7eefd06d2ec7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "user_le = LabelEncoder()\n",
        "item_le = LabelEncoder()\n",
        "\n",
        "df_train['user_id'] = user_le.fit_transform(df_train['user_id'])\n",
        "df_train['item_id'] = item_le.fit_transform(df_train['item_id'])\n",
        "\n",
        "df_test['user_id'] = user_le.transform(df_test['user_id'])\n",
        "df_test['item_id'] = item_le.transform(df_test['item_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ef3e2f-792d-4511-b4d0-74495d9cb30b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ef3e2f-792d-4511-b4d0-74495d9cb30b",
        "outputId": "07268aa5-5ddb-4bbb-8384-713dfc035a91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5365, 5364)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_train['user_id'].nunique(), df_train['user_id'].max()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['item_id'].nunique(), df_train['item_id'].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiZDH0OfgEt0",
        "outputId": "8e29f7b4-6294-4939-d5a2-da5ade5d2367"
      },
      "id": "oiZDH0OfgEt0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3010, 3009)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "q0BgWID2gJIC"
      },
      "id": "q0BgWID2gJIC"
    },
    {
      "cell_type": "markdown",
      "id": "3d356df8-9157-4752-b30d-dc80aba5e53c",
      "metadata": {
        "id": "3d356df8-9157-4752-b30d-dc80aba5e53c"
      },
      "source": [
        "##### Задание 1. Напишем функцию, которая превратит датафрейм в матрицу интеракций. В функции df_to_matrix реализуйте функцию, которая принимает датафрейм и возвращает np.array матрицу интеракций. В функции df_to_coo реализуйте функцию, которая принимает датафрейм и возвращает разреженную матрицу интеракций в coo_array формате"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d38a7bb7-7f2d-4957-8dac-6397af9b1645",
      "metadata": {
        "id": "d38a7bb7-7f2d-4957-8dac-6397af9b1645"
      },
      "outputs": [],
      "source": [
        "def df_to_matrix(df: pd.DataFrame) -> np.ndarray:\n",
        "    interaction_matrix = df_train.pivot_table(index='user_id', columns='item_id', values='rating', fill_value=0)\n",
        "    result = interaction_matrix.values\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55362cbb-5e2d-455b-afd1-8507f1dd51ba",
      "metadata": {
        "id": "55362cbb-5e2d-455b-afd1-8507f1dd51ba"
      },
      "outputs": [],
      "source": [
        "interactions = df_to_matrix(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверим корректность размера матрицы\n",
        "assert interactions.shape[0] == 5365\n",
        "assert interactions.shape[1] == 3010"
      ],
      "metadata": {
        "id": "T5PQy8zDgkV_"
      },
      "id": "T5PQy8zDgkV_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions[:10, :10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inX8eEe2f7AW",
        "outputId": "90e7e0a5-f780-4f8d-c2f8-1dd81aee9bde"
      },
      "id": "inX8eEe2f7AW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 2., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [5., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794b646d-a560-42dd-a466-87cad2589271",
      "metadata": {
        "id": "794b646d-a560-42dd-a466-87cad2589271"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import coo_array\n",
        "\n",
        "def df_to_coo(df: pd.DataFrame) -> coo_array:\n",
        "    interaction_matrix = df_train.pivot_table(index='user_id', columns='item_id', values='rating', fill_value=0)\n",
        "    matrix = interaction_matrix.values\n",
        "\n",
        "    row_indices, col_indices = np.nonzero(matrix)\n",
        "    values = matrix[row_indices, col_indices]\n",
        "\n",
        "    result = coo_array((values, (row_indices, col_indices)), shape=matrix.shape)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30f9c218-0419-41b2-a112-c2214fad1d99",
      "metadata": {
        "id": "30f9c218-0419-41b2-a112-c2214fad1d99"
      },
      "outputs": [],
      "source": [
        "coo_interactions = df_to_coo(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coo_interactions.toarray()[:10, :10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIIqMI0Cjk1C",
        "outputId": "0999065a-699f-4f20-a3e2-1815867d8b91"
      },
      "id": "oIIqMI0Cjk1C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 2., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [5., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96b57a7a-0551-4f75-8047-fb9904ac93df",
      "metadata": {
        "id": "96b57a7a-0551-4f75-8047-fb9904ac93df"
      },
      "outputs": [],
      "source": [
        "assert (interactions != 0).sum() == df_train.shape[0]\n",
        "assert interactions[0, 2994] == 3\n",
        "assert interactions[2369, 1203] == 5\n",
        "assert interactions[1557, 459] == 3\n",
        "assert np.allclose(coo_interactions.toarray(), interactions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b3862a-e62a-4ebe-a70c-29102e9f99fd",
      "metadata": {
        "id": "93b3862a-e62a-4ebe-a70c-29102e9f99fd"
      },
      "source": [
        "##### Задание 2.1. Рассмотрим [SVD](https://en.wikipedia.org/wiki/Singular_value_decomposition). Возьмите готовую реализуцию алгоритма из numpy.linalg или из scipy.linalg и примените алгоритм к матрицам интеракций, полученным в первом задании. Для работы со sparse матрицей обычная реализация svd не подойдет и нужно будет воспользоваться scipy.sparse.linalg.svds. Вам нужно разложить матрицу интеракций на 3 матрицы U, S, V, а затем перемножить их и восстановить изначальную матрицу. При полном разложении исходная матрица должна восстанавливаться максимально хорошо"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eead134a-9aac-4027-b0b8-592de614c3d0",
      "metadata": {
        "id": "eead134a-9aac-4027-b0b8-592de614c3d0"
      },
      "outputs": [],
      "source": [
        "def make_svd(interractions: Union[np.ndarray, coo_array], n_singular_values: int = -1):\n",
        "    # функция должна работать и для полной матрицы и для sparse матрицы(вам поможет isinstance).\n",
        "    # если n_singular_values = -1, то берем все сингулярные числа для полной матрицы\n",
        "    # и все кроме одного сингулярного числа для coo-матрицы(иначе scipy.sparse.linalg.svds не будет работать)\n",
        "\n",
        "\n",
        "    #your code here\n",
        "\n",
        "    return U, S, V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c5fecd4-4739-4f6b-9c9c-44bde8b66a34",
      "metadata": {
        "id": "5c5fecd4-4739-4f6b-9c9c-44bde8b66a34"
      },
      "outputs": [],
      "source": [
        "U, S, V = make_svd(interactions)\n",
        "assert np.allclose(U @ S @ V, interactions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5a5f59e-3832-4a7d-95b4-856531582bbd",
      "metadata": {
        "id": "c5a5f59e-3832-4a7d-95b4-856531582bbd"
      },
      "outputs": [],
      "source": [
        "U1, S1, V1 = make_svd(interactions, 10)\n",
        "U, S, V = make_svd(coo_interactions, 10)\n",
        "assert np.allclose(U1 @ S1 @ V1, U @ S @ V)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9443daa6-e9f1-414a-8107-5a3016452929",
      "metadata": {
        "id": "9443daa6-e9f1-414a-8107-5a3016452929"
      },
      "source": [
        "##### Задание 2.2. Теперь попробуем сделать рекомендации с помощью SVD. Мы научились восстанавливать исходную матрицу с помощью разложения, теперь же мы хотим порекомендовать пользователю айтемы, которые будут для него максимально релевантны(в восстановленной матрице у них будет самый высокий скор). Для каждого пользователя нужно будет найти индексы айтемов, которые имеют максимальный скор. При этом стоит обратить внимание, что мы не хотим рекомендовать пользователю айтемы, с которыми он уже взаимодействовал"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "787da18f-48d0-4dfa-b18f-b7e97cc98a4f",
      "metadata": {
        "id": "787da18f-48d0-4dfa-b18f-b7e97cc98a4f"
      },
      "outputs": [],
      "source": [
        "def make_svd_recommendations(interractions: Union[np.ndarray, coo_array], n_singular_values: int = -1, top_k: int = 100):\n",
        "    # Возвращает матрицу вида n_users, top_k, то есть для каждого пользователя возвращаем индексы\n",
        "    # top_k самых релевантный айтемов среди тех с которыми он еще не взаимодействовал\n",
        "\n",
        "    #your code here\n",
        "\n",
        "\n",
        "    return recommendations #shape ~ [n_users, top_k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec72f3dd-c8f2-4434-b84e-ef016c4773a1",
      "metadata": {
        "id": "ec72f3dd-c8f2-4434-b84e-ef016c4773a1"
      },
      "outputs": [],
      "source": [
        "recs = make_svd_recommendations(interractions, -1, 100)\n",
        "assert recs.shape == (interractions.shape[0], 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5d0b788-855a-4fd9-8cbb-38c0dd289ef5",
      "metadata": {
        "id": "f5d0b788-855a-4fd9-8cbb-38c0dd289ef5"
      },
      "source": [
        "##### Задание 2.3. Теперь давайте посмотрим как будет зависеть качетво рекомендаций, от количества сингулярных чисел, которые мы возьмем в SVD разложении. Переберите n_singular_values из списка [1, 10, 50, 200, 1000] и посмотрите как будет изменяться метрика NDCG на тестовом датасете для таких рекомендаций и как будет меняться время вычисления. Для каждого графики зависимости метрики NDCG от n_singular_values и времени работы алгоритма от n_singular_values(Время работы будет меняться только для sparse-матрицы, стоит запускать алгоритм именно для нее)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dcg(scores) :\n",
        "    return np.sum(np.divide(np.power(2, scores) - 1,\n",
        "                            np.log2(np.arange(scores.shape[0], dtype=np.float64) + 2)), dtype=np.float64)\n",
        "\n",
        "def ndcg_metric(gt_items, predicted):\n",
        "    '''\n",
        "    Функция для расчета NDGC\n",
        "    '''\n",
        "    at = len(predicted)\n",
        "    relevance = np.array([1 if x in predicted else 0 for x in gt_items])\n",
        "    # DCG uses the relevance of the recommended items\n",
        "    rank_dcg = dcg( relevance)\n",
        "    if rank_dcg == 0.0:\n",
        "        return 0.0\n",
        "    # IDCG has all relevances to 1 (or the values provided), up to the number of items in the test set that can fit in the list length\n",
        "    ideal_dcg = dcg(np.sort(relevance)[::-1][:at])\n",
        "    if ideal_dcg = 0.0:\n",
        "        return 0.0\n",
        "    ndcg_ = rank_dcg / ideal_dcg\n",
        "    return ndcg_\n",
        "\n",
        "def evaluate_recommender(df, model_preds, gt_col=\"test_interactions\", topn=10):\n",
        "    metric_values = []\n",
        "    for idx, row in df.iterrows():\n",
        "        gt_items = row[gt_col]\n",
        "        metric_values.append((ndcg_metric(gt_items, row[model_preds])))\n",
        "    return (\"ndcg\": np.mean(metric_values))"
      ],
      "metadata": {
        "id": "m-SKUkIxq3Vb"
      },
      "id": "m-SKUkIxq3Vb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f931fd-0eb0-4965-9e02-e005ed545c71",
      "metadata": {
        "id": "06f931fd-0eb0-4965-9e02-e005ed545c71"
      },
      "outputs": [],
      "source": [
        "def plot_graphs(interractions: Union[np.ndarray, coo_array], top_k: int = 100):\n",
        "    #your code here\n",
        "    for n_singular_values in [1, 10, 50, 200, 1000]:\n",
        "        #your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee22fe02-b1c2-4fb5-a7b1-0525356fe9f0",
      "metadata": {
        "id": "ee22fe02-b1c2-4fb5-a7b1-0525356fe9f0"
      },
      "outputs": [],
      "source": [
        "plot_graphs()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8612d96-c694-42d6-9525-58808f642577",
      "metadata": {
        "id": "a8612d96-c694-42d6-9525-58808f642577"
      },
      "source": [
        "##### Задание 3.1. Перейдем к [ALS](http://yifanhu.net/PUB/cf.pdf). Возьмем реализацию iALS из библиотеки [implicit](https://benfred.github.io/implicit/api/models/cpu/als.html). Обучите ALS на нашем датасете, сделайте top_k рекомендации для юзеров из тестового датасета, и сравните метрики ALS с метриками, которые получились в SVD. Попробуйте перебрать гиперпараметры и найдите оптимальное число факторов, коэффициент alpha и коэффициент регуляризации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5fb16e9-49d1-4d7e-a384-ccbdad4f1cdf",
      "metadata": {
        "id": "b5fb16e9-49d1-4d7e-a384-ccbdad4f1cdf"
      },
      "outputs": [],
      "source": [
        "def make_als_recommendations(\n",
        "    interractions: Union[np.ndarray, coo_array],\n",
        "    top_k: int = 100,\n",
        "    n_factors: int = 100,\n",
        "    alpha: float = 1.0,\n",
        "    regularization: float = 0.01,\n",
        "):\n",
        "    #your code here\n",
        "\n",
        "\n",
        "    return recommendations #shape ~ [n_users, top_k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5573d01-8512-450f-9260-03928ee9b367",
      "metadata": {
        "id": "b5573d01-8512-450f-9260-03928ee9b367"
      },
      "outputs": [],
      "source": [
        "recs = make_als_recommendations(interractions)\n",
        "assert recs.shape == (interractions.shape[0], 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81f3b1cc-760b-4d6a-ab8a-aca57b7b6dfe",
      "metadata": {
        "id": "81f3b1cc-760b-4d6a-ab8a-aca57b7b6dfe"
      },
      "source": [
        "##### Задание 3.2. Сделайте объяснение рекомендаций для нескольких юзеров(als.explain). Воспользуйтесь файлом movies.dat чтобы перейти от индексов фильмов к их названием"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddd9a956-d2f5-4560-8d0c-c72164ebdfa8",
      "metadata": {
        "id": "ddd9a956-d2f5-4560-8d0c-c72164ebdfa8"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d7ea0c-8288-45f5-83d4-9761a8952669",
      "metadata": {
        "id": "d7d7ea0c-8288-45f5-83d4-9761a8952669"
      },
      "source": [
        "##### Задание 4. До этого мы работали с рейтингами, но как обсуждалось на лекции, implicit ALS отлично работает и с implicit фидбэком. Давайте попробуем преобразовать наш датасет(трейн и тест) следующим образом\n",
        "\n",
        "1. Бинаризуем все рейтинги(заменим любую интеракцию пользователя на 1)\n",
        "2. Заменим на 1 только рейтинги 4 и 5, а рейтинг ниже 4 заменим на 0\n",
        "3. Заменим на 1 только рейтинги 4 и 5, а рейтинг ниже 4 заменим на -1\n",
        "4. Заменим на 1 только рейтинги 4 и 5, а рейтинг ниже 4 заменим на -1 и добавим сглаживание по времени. То есть чем дальше была интеракция от максимальной даты трейна, тем с меньшим весом мы будем ее учитывать(например можно интеракции за последний месяц брать в исходном виде, и с каждым месяцем в прошлое умножать их на какой-нибудь коэффициент меньший 1). Таким образом более старые интеракции пользователя будут вносить меньший вклад в его интересы\n",
        "5. Придумайте свой вариант(опционально)\n",
        "\n",
        "Для каждой полученной матрицы обучите iALS и SVD и сравните их результаты между собой(преобразовывать нужно только обучающую выборку, тестовую оставляем неизменной)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c839fd09-eca4-43e0-a209-2da63775f79f",
      "metadata": {
        "id": "c839fd09-eca4-43e0-a209-2da63775f79f"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee7a03b1-5072-4bc4-ba46-1fc3c989b888",
      "metadata": {
        "id": "ee7a03b1-5072-4bc4-ba46-1fc3c989b888"
      },
      "source": [
        "##### Задание 5. iALS на numpy/torch. Давайте реализуем алгоритм iALS на нумпае или торче. Требуется реализовать алгорит, описанный в 4 части [статьи](http://yifanhu.net/PUB/cf.pdf). Обратите внимания на все оптимизации, которые они описывают в статье, чтобы сократить лишние вычисления. Hint: метрики у вашего алгоритма должны быть сравнимы с метриками ALS из библиотеки implicit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6be5f0d-1454-4f15-9dd1-17d1f1f99583",
      "metadata": {
        "id": "e6be5f0d-1454-4f15-9dd1-17d1f1f99583"
      },
      "outputs": [],
      "source": [
        "class iALS:\n",
        "    def __init__(self, n_factors: int = 100, alpha: float = 1.0, reg_coef = 0.01):\n",
        "        #your code here\n",
        "\n",
        "    def fit(self, interractions: np.ndarray, n_iterations: int 10):\n",
        "        #your code here\n",
        "\n",
        "    def predict(self, top_k: int = 100):\n",
        "        # возвращает top-k айтемов для каждого юзера(айтемы с которыми юзер взаимодействовал не должны попасть в рекомендации)\n",
        "        #your code here\n",
        "\n",
        "        return predicts # shape ~ [n_users, top_k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9aa65d7-11dc-48d9-a270-8d0a6d96f28e",
      "metadata": {
        "id": "a9aa65d7-11dc-48d9-a270-8d0a6d96f28e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "recsys_course",
      "language": "python",
      "name": "recsys_course"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}