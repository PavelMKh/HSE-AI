{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP3QpbyFWZCp"
      },
      "source": [
        "## ДЗ №3 Двухуровневый пайплайн\n",
        "#### В этой домашке вам предстоит написать с нуля двустадийную рекомендательную систему.\n",
        "\n",
        "#### Дата выдачи: 10.03.25\n",
        "\n",
        "#### Мягкий дедлайн: 31.03.25 23:59 MSK\n",
        "\n",
        "#### Жесткий дедлайн: 7.04.25 23:59 MSK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSlPlfnkWZCq"
      },
      "source": [
        "### Описание\n",
        "Это творческое задание, в котором вам необходимо реализовать полный цикл построения рекомендательной системы: реализовать кандидат генераторов, придумать и собрать признаки, обучить итоговый ранкер и заинференсить модели на всех пользователей.\n",
        "\n",
        "Вам предоставляется два набора данных: `train.csv` и `test.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cdzC4oEVWZCr"
      },
      "outputs": [],
      "source": [
        "# скачиваем данные\n",
        "# если из этой ячейки не получается, то вот ссылка на папку https://drive.google.com/drive/folders/1HT0Apm8Jft0VPLJtdBBUGu9s1M7vZcoJ?usp=drive_link\n",
        "\n",
        "# !pip3 install gdown\n",
        "\n",
        "\n",
        "# import gdown\n",
        "# # train\n",
        "# url = \"https://drive.google.com/file/d/1-CcS22-UpTJeNcFlA0dVLrEQn8jnI0d-/view?usp=drive_link\"\n",
        "# output = 'train.csv'\n",
        "# gdown.download(url, output, quiet=False)\n",
        "\n",
        "# # test\n",
        "# url = \"https://drive.google.com/file/d/11iz3xDh0IIoEIBY0dyRSvByY3qfiT3BG/view?usp=drive_link\"\n",
        "# output = 'test.csv'\n",
        "# gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install"
      ],
      "metadata": {
        "id": "-1sK7HXhYzN6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from typing import Union\n",
        "from scipy.sparse.linalg import svds\n",
        "from scipy.sparse import coo_matrix, coo_array, csr_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "np.random.seed(RANDOM_STATE)"
      ],
      "metadata": {
        "id": "P_xxRVlgX6JU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train_part.csv')\n",
        "df_valid = pd.read_csv('test_part.csv')\n",
        "\n",
        "train_end = '2021-07-21' # при таком разбиении в тест попадет примерно 25% наблюдений\n",
        "df_train = df[df['last_watch_dt'] < train_end].copy()\n",
        "df_test = df[df['last_watch_dt'] >= train_end].copy()\n",
        "df_train.shape, df_test.shape"
      ],
      "metadata": {
        "id": "P3euMLYoXzgI",
        "outputId": "88919f0e-b98d-4760-8199-2f7f5019865d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3649400, 6), (1217556, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_users = df_train['user_id'].unique()\n",
        "train_items = df_train['item_id'].unique()\n",
        "\n",
        "df_test = df_test[df_test['user_id'].isin(train_users)]\n",
        "df_test = df_test[df_test['item_id'].isin(train_items)]\n",
        "df_test.shape"
      ],
      "metadata": {
        "id": "VCtbuPkVqWH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ввиду того, что тестовый датафрейм достаточно большой, время вычисления в Colab очень продолжительное. Выполним семплирование для обучающего и тестового датафрейма."
      ],
      "metadata": {
        "id": "D1JVqAklgcLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_user_ids = df_train['user_id'].unique()\n",
        "\n",
        "selected_user_ids = np.random.choice(unique_user_ids, size=2000, replace=False)\n",
        "df_train_sample = df_train[df_train['user_id'].isin(selected_user_ids)]\n",
        "df_test_sample = df_test[df_test['user_id'].isin(selected_user_ids)]"
      ],
      "metadata": {
        "id": "iBQlglHqna_7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train_sample.shape)\n",
        "print(df_test_sample.shape)"
      ],
      "metadata": {
        "id": "mZucysU1g0Ac",
        "outputId": "e2d39cb7-651c-4e49-ad13-95bf83d2c538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11080, 6)\n",
            "(921, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train_sample.user_id.unique())"
      ],
      "metadata": {
        "id": "VzTwhi33m-KF",
        "outputId": "892def89-e3c8-4511-98e5-35770286cadd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train_sample.item_id.unique())"
      ],
      "metadata": {
        "id": "c9vfN6QonD4w",
        "outputId": "106099ca-e32c-4113-f160-1917003d6ffa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2562"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt2QAsgMWZCr"
      },
      "source": [
        "\n",
        "\n",
        "### 1 Этап. Модели первого уровня. (max 3 балла)\n",
        "В этом этапе вам необходимо разделить `train` датасет на 2 части: для обучения моделей первого уровня и для их валидации. Единственное условие для разбиения – разбивать нужно по времени. Данные для обучение будем называть `train_stage_1`, данные для валидации `valid_stage_1`. Объемы этих датасетов вы определяет самостоятельно.\n",
        "\n",
        "Для начала нам нужно отобрать кандидатов при помощи легких моделей. Необходимо реализовать 3 типа моделей:\n",
        "1. Любая эвристическая(алгоритмичная) модель на ваш выбор **(0.5 балл)**\n",
        "2. Любая матричная факторизация на ваш выбор **(1 балл)**\n",
        "3. Любая нейросетевая модель на ваш выбор **(1 балла)**\n",
        "\n",
        "Не забудьте использовать скор каждой модели, как признак!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_matrix = df_train.pivot_table(index='user_id', columns='item_id', aggfunc=lambda x: 1, fill_value=0)\n",
        "result = interaction_matrix.values"
      ],
      "metadata": {
        "id": "cWQwOH8nfwfU",
        "outputId": "bcabe4f5-58c0-42ec-9cf3-6ecacf898a65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-6a34016da947>:1: PerformanceWarning: The following operation may generate 13574330978 cells in the resulting pandas object.\n",
            "  interaction_matrix = df_train.pivot_table(index='user_id', columns='item_id', aggfunc=lambda x: 1, fill_value=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[:5, :5]"
      ],
      "metadata": {
        "id": "_Q2RYOW-f-qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Напишем класс для матричной факторизации в форме SVD\n",
        "class SVD_factorization():\n",
        "\n",
        "  def __init__(self, n_singular_values: int = -1, top_k: int = 100) -> None:\n",
        "      self.n_singular_values = n_singular_values\n",
        "      self.top_k = top_k\n",
        "      self.recs = None\n",
        "\n",
        "  def _df_to_matrix(self, df: pd.DataFrame) -> np.ndarray:\n",
        "    interaction_matrix = df_train.pivot_table(index='user_id', columns='item_id', values='rating', fill_value=0)\n",
        "    result = interaction_matrix.values\n",
        "    return result\n",
        "\n",
        "\n",
        "  def _make_svd(self, interractions: Union[np.ndarray, coo_array]):\n",
        "    if isinstance(interractions, np.ndarray):\n",
        "        U, S, Vt = np.linalg.svd(interractions, full_matrices=False)\n",
        "        if n_singular_values != -1:\n",
        "            U = U[:, :n_singular_values]\n",
        "            S = S[:n_singular_values]\n",
        "            Vt = Vt[:n_singular_values, :]\n",
        "\n",
        "    elif isinstance(interractions, coo_array):\n",
        "        if n_singular_values == -1:\n",
        "            n_singular_values = interractions.shape[1] - 1\n",
        "\n",
        "        U, S, Vt = svds(interractions, k=self.n_singular_values)\n",
        "\n",
        "    if n_singular_values != -1:\n",
        "            U = U[:, :self.n_singular_values]\n",
        "            S = S[:self.n_singular_values]\n",
        "            Vt = Vt[:self.n_singular_values, :]\n",
        "\n",
        "    return U, S, Vt\n",
        "\n",
        "  def fit(self, df_train: pd.DataFrame):\n",
        "    interractions = self._df_to_matrix(df_train)\n",
        "\n",
        "    U, S, Vt = self.make_svd(interractions, self.n_singular_values)\n",
        "\n",
        "    predicted_ratings = np.dot(np.dot(U, np.diag(S)), Vt)\n",
        "\n",
        "    n_users, n_items = predicted_ratings.shape\n",
        "\n",
        "    recommendations = np.zeros((n_users, self.top_k), dtype=int)\n",
        "\n",
        "    for user in range(n_users):\n",
        "        interacted_items = np.where(interractions[user] > 0)[0]\n",
        "\n",
        "        user_ratings = predicted_ratings[user]\n",
        "\n",
        "        user_ratings[interacted_items] = -np.inf\n",
        "\n",
        "        top_k_indices = np.argsort(user_ratings)[-self.top_k:][::-1]\n",
        "\n",
        "        recommendations[user] = top_k_indices\n",
        "\n",
        "    self.resc = recommendations\n",
        "\n",
        "  def _dcg(scores) :\n",
        "    return np.sum(np.divide(np.power(2, scores) - 1,\n",
        "                            np.log2(np.arange(scores.shape[0], dtype=np.float64) + 2)), dtype=np.float64)\n",
        "\n",
        "  def _ndcg_metric(self, gt_items, predicted):\n",
        "    '''\n",
        "    Функция для расчета NDGC\n",
        "    '''\n",
        "    at = len(predicted)\n",
        "    relevance = np.array([1 if x in predicted else 0 for x in gt_items])\n",
        "    rank_dcg = self.dcg( relevance)\n",
        "    if rank_dcg == 0.0:\n",
        "        return 0.0\n",
        "    ideal_dcg = self.dcg(np.sort(relevance)[::-1][:at])\n",
        "    if ideal_dcg == 0.0:\n",
        "        return 0.0\n",
        "    ndcg_ = rank_dcg / ideal_dcg\n",
        "    return ndcg_\n",
        "\n",
        "  def _evaluate_recommender(self, df_test: pd.DataFrame, gt_col=\"test_interactions\", predict_col='recs', topn=10):\n",
        "      user_ids = range(len(self.recs))\n",
        "      recs_df_grouped = pd.DataFrame({'user_id': user_ids})\n",
        "      recs_df_grouped['recs'] = [list(row) for row in self.recs]\n",
        "      test_df_grouped = df_test.groupby('user_id').apply(lambda x: list(x['item_id']), include_groups=False).reset_index(name='test_interactions')\n",
        "      result_df = test_df_grouped.merge(recs_df_grouped[['user_id', 'recs']], on='user_id', how='left')\n",
        "\n",
        "      metric_values = []\n",
        "      for idx, row in result_df.iterrows():\n",
        "          gt_items = row[gt_col]\n",
        "          model_preds = row[predict_col]\n",
        "          metric_values.append((self.ndcg_metric(gt_items, model_preds)))\n",
        "      return {\"ndcg\": np.mean(metric_values)}\n",
        ""
      ],
      "metadata": {
        "id": "LonBXwu_ZMm7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mf = SVD_factorization()\n",
        "\n",
        "mf.fit(df_train)"
      ],
      "metadata": {
        "id": "WHSFHeIleYlS",
        "outputId": "326f8921-a9c2-489f-da3d-d97c47895a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'rating'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ebc27825cdd1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVD_factorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-f507d305060e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, df_train)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0minterractions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterractions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_singular_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-f507d305060e>\u001b[0m in \u001b[0;36m_df_to_matrix\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_df_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0minteraction_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteraction_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot_table\u001b[0;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m   9507\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9509\u001b[0;31m         return pivot_table(\n\u001b[0m\u001b[1;32m   9510\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9511\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pivot_table\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     table = __internal_pivot_table(\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36m__internal_pivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mto_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'rating'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grphavZ7WZCr"
      },
      "outputs": [],
      "source": [
        "my_heuristic_model = # YOUR CODE HERE\n",
        "my_matrix_factorization = # YOUR CODE HERE\n",
        "my_neural_network = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIgaWPh4WZCs"
      },
      "source": [
        "Каждая модель должна уметь:\n",
        "1) для пары user_item предсказывать скор релевантности (масштаб скора не важен), важно обработать случаи, когда модель не можеn проскорить пользователя или айтем, вместо этого вернуть какое-то дефолтное значение\n",
        "2) для всех пользователей вернуть top-k самых релевантных айтемов (тут вам скоры не нужны)\n",
        "\n",
        "\n",
        "Дополнительно можно провести анализ кандидат генератов, измерить насколько различные айтемы они рекомендуют, например с помощью таких метрик как: [Ranked based overlap](https://github.com/changyaochen/rbo) или различные вариации [Diversity](https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation/blob/master/Base/Evaluation/metrics.py#L289). **(1 балл)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTeoyEtiWZCs"
      },
      "source": [
        "\n",
        "### 2 Этап. Генерация и сборка признаков. (max 2 балла)\n",
        "Необходимо собрать минимум 10 осмысленных (`np.radndom.rand()` не подойдет) признаков, при этом:\n",
        "1. 2 должны относиться только к сущности \"пользователь\" (например средний % просмотра фильмов у этой возрастной категории)\n",
        "2. 2 должны относиться только к сущности \"айтем\" (например средний средний % просмотра данного фильма)\n",
        "3. 6 признаков, которые показывают связь пользователя и айтема (например средний % просмотра фильмов с данным актером (айтем) у пользователей с таким же полом (пользователь)).\n",
        "\n",
        "### ВАЖНО!  \n",
        "\n",
        "1. **В датасете есть колонка `watched_prct`. Ее можно использовать для генерации признаков (например сколько пользователь в среднем смотрит фильмы), но нельзя подавать в модель, как отдельную фичу, потому что она напрямую связана с target.**\n",
        "2. **Все признаки должны быть собраны без дата лика, то есть если пользователь посмотрел фильм 10 августа, то признаки мы можем считать только на данных до 9 августа включительно.**\n",
        "\n",
        "\n",
        "### Разбалловка\n",
        "Обучение ранкера будет проходить на `valid_stage_1`, как  раз на которой мы валидировали модели, а тестировать на `test`. Поэтому есть 2 варианта сборки признаков, **реализовать нужно только 1 из них:**\n",
        "1. Для обучения собираем признаки на первый день `valid_stage_1`, а для теста на первый день `test`. Например, если `valid_stage_1` начинается 5 сентября, то все признаки мы можем собирать только по 4 сентября включительно. **(1 балл)**\n",
        "2. Признаки будем собирать честно на каждый день, то есть на 5 сентября собираем с начала до 4, на 6 сентября с начала до 5 и т.д. **(2 балла)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhGi2EDvWZCs"
      },
      "outputs": [],
      "source": [
        "train_df_with_features = # YOUR CODE IS HERE\n",
        "test_df_with_features = # YOUR CODE IS HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unxssAkSWZCs"
      },
      "source": [
        "\n",
        "### 3 Этап. Обучение финального ранкера (max 2 балла)\n",
        "Собрав все признаки из этапа 2, добавив скоры моделей из этапа 1 для каждой пары пользователь-айтем (где это возможно), пришло время обучать ранкер. В качестве ранкера можно использовать либо [xgboost](https://xgboost.readthedocs.io/en/stable/) или [catboost](https://catboost.ai/). Обучать можно как `Classfier`, так и `Ranker`, выбираем то, что лучше сработает. Обучение ранкера будет проходить на `valid_stage_1`, как  раз на которой мы валидировали модели, а тестировать на `test`, которую мы до сих пор не трогали.  Заметьте, что у нас в тесте есть холодные пользователи – те, кого не было в train и активные – те, кто был в train. Возможно их стоит обработать по отдельности (а может и нет).  \n",
        "(1 балл)\n",
        "\n",
        "После получения лучшей модели надо посмотреть на важность признаков и [shap values](https://shap.readthedocs.io/en/latest/index.html), чтобы:\n",
        "1. Интерпритировать признаки, которые вы собрали, насколько они полезные\n",
        "2. Проверить наличие ликов – если важность фичи в 100 раз больше, чем у всех остальных, то явно что-то не то  \n",
        "\n",
        "(1 балл)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9156MH9rWZCs"
      },
      "outputs": [],
      "source": [
        "# YOUR FIT PREDICT CODE HERE\n",
        "model.fit()\n",
        "model.predict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPj0Q0PaWZCs"
      },
      "source": [
        "\n",
        "### 4 Этап. Инференс лучшего ранкера (max 3 балла)\n",
        "\n",
        "Теперь мы хотим построить рекомендации \"на завтра\", для этого нам нужно:\n",
        "\n",
        "1. Обучить модели первого уровня на всех (train+test) данных (0.5 балла)\n",
        "2. Для каждой модели первого уровня для каждого пользователя сгененировать N кандидатов (0.5 балла)\n",
        "3. \"Склеить\" всех кандидатов для каждого пользователя (дубли выкинуть), посчитать скоры от всех моделей (0.5 балла)\n",
        "4. Собрать фичи для ваших кандидатов (теперь можем считать признаки на всех данных) (0.5 балла)\n",
        "5. Проскорить всех кандидатов бустингом и оставить k лучших (0.5 балла)\n",
        "6. Посчитать разнообразие(Diversity) и построить график от Diversity(k) (0.5 балла)\n",
        "\n",
        "\n",
        "Все гиперпараметры (N, k) определяете только Вы!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2I1t1N7WZCt"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}